{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import deeplabcut\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calibration file: 20211029_checkerboard_cal01\n",
    "\n",
    "videos: trial 1-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the 3D DeepLabCut project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the base path for each different 3D project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing 3d project\n"
     ]
    }
   ],
   "source": [
    "config_path_3d = os.path.join(base_path, 'config.yaml')\n",
    "\n",
    "if os.path.exists(config_path_3d):\n",
    "    print('Found existing 3d project')\n",
    "else:\n",
    "    print('Create new 3d project!')\n",
    "    deeplabcut.create_new_project_3d('UpAndDown','Ming', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you edit the 3D config.yaml file. The cameras should be named 'rear' and 'lateral', and the config file paths for the 2D tracking should be updated correctly. Also update the skeleton to match the 2D tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/Overviewof3D.md for an overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code below is modified from the DLC repository here: https://github.com/DeepLabCut/DeepLabCut/blob/master/deeplabcut/pose_estimation_3d/camera_calibration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of internal corners on our checkboard. (e.g., 8x8 squares has 7x7 internal corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbrow = 7\n",
    "cbcol = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_names = ['rear', 'lateral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "framedir = os.path.join(base_path, 'calibration_images')\n",
    "cornerdir = os.path.join(base_path, 'corners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\rear-011.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\rear-012.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\rear-013.jpg']\n",
      " ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\lateral-011.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\lateral-012.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\calibration_images\\\\lateral-013.jpg']]\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for cam1 in cam_names:\n",
    "    fn1 = glob.glob(os.path.join(framedir, cam1 + '*.jpg'))\n",
    "    fn1.sort()\n",
    "    filenames.append(fn1)\n",
    "\n",
    "filenames = np.array(filenames)\n",
    "\n",
    "print(filenames[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotategrid = [False, True]\n",
    "mirror = [False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((cbrow * cbcol, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:cbcol, 0:cbrow].T.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rear-011\n",
      "Found!\n",
      "rear-012\n",
      "Found!\n",
      "rear-013\n",
      "Found!\n",
      "rear-014\n",
      "Found!\n",
      "rear-015\n",
      "Found!\n",
      "rear-016\n",
      "Found!\n",
      "rear-017\n",
      "Found!\n",
      "rear-018\n",
      "Found!\n",
      "rear-019\n",
      "Found!\n",
      "lateral-011\n",
      "Found!\n",
      "lateral-012\n",
      "Found!\n",
      "lateral-013\n",
      "Found!\n",
      "lateral-014\n",
      "Found!\n",
      "lateral-015\n",
      "Found!\n",
      "lateral-016\n",
      "Found!\n",
      "lateral-017\n",
      "Found!\n",
      "lateral-018\n",
      "Found!\n",
      "lateral-019\n",
      "Found!\n"
     ]
    }
   ],
   "source": [
    "img_shape = {}\n",
    "objpoints = {}  # 3d point in real world space\n",
    "imgpoints = {}  # 2d points in image plane.\n",
    "dist_pickle = {}\n",
    "stereo_params = {}\n",
    "for cam in cam_names:\n",
    "    objpoints.setdefault(cam, [])\n",
    "    imgpoints.setdefault(cam, [])\n",
    "    dist_pickle.setdefault(cam, [])\n",
    "\n",
    "for cam, camfiles1, rot1, mirror1 in zip(cam_names, filenames, rotategrid, mirror):\n",
    "    for fn1 in camfiles1:\n",
    "        img = cv2.imread(fn1)\n",
    "        if mirror1:\n",
    "            img = cv2.flip(img, 1)  # flip horizontally\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        pn, fn = os.path.split(fn1)\n",
    "        fn, ext = os.path.splitext(fn)\n",
    "\n",
    "        print('{}'.format(fn))\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (cbrow,cbcol), cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "\n",
    "        if ret:\n",
    "            print('Found!')\n",
    "            if rot1:\n",
    "                corners = corners.reshape((cbrow,cbcol, -1))\n",
    "                corners = corners.transpose((1, 0, 2))\n",
    "                corners = corners.reshape((cbrow*cbcol, 1, -1))\n",
    "            \n",
    "            img_shape[cam] = gray.shape[::-1]\n",
    "            objpoints[cam].append(objp)\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints[cam].append(corners)            \n",
    "        else:\n",
    "            print('Not found')\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (cbrow,cbcol), corners, ret)\n",
    "\n",
    "        cv2.imwrite(os.path.join(cornerdir, fn + '_corner.jpg'), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_camera_matrix = os.path.join(base_path,'camera_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intrinsic camera calibration matrices for rear as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\camera_matrix\n",
      "Mean re-projection error for rear images: 0.178 pixels \n",
      "Saving intrinsic camera calibration matrices for lateral as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\camera_matrix\n",
      "Mean re-projection error for lateral images: 0.217 pixels \n"
     ]
    }
   ],
   "source": [
    "for cam in cam_names:\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints[cam], imgpoints[cam], img_shape[cam], None, None\n",
    "    )\n",
    "\n",
    "    # Save the camera calibration result for later use (we won't use rvecs / tvecs)\n",
    "    dist_pickle[cam] = {\n",
    "        \"mtx\": mtx,\n",
    "        \"dist\": dist,\n",
    "        \"objpoints\": objpoints[cam],\n",
    "        \"imgpoints\": imgpoints[cam],\n",
    "    }\n",
    "    pickle.dump(\n",
    "        dist_pickle,\n",
    "        open(\n",
    "            os.path.join(path_camera_matrix, cam + \"_intrinsic_params.pickle\"),\n",
    "            \"wb\",\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"Saving intrinsic camera calibration matrices for %s as a pickle file in %s\"\n",
    "        % (cam, os.path.join(path_camera_matrix))\n",
    "    )\n",
    "\n",
    "    # Compute mean re-projection errors for individual cameras\n",
    "    mean_error = 0\n",
    "    for i in range(len(objpoints[cam])):\n",
    "        imgpoints_proj, _ = cv2.projectPoints(\n",
    "            objpoints[cam][i], rvecs[i], tvecs[i], mtx, dist\n",
    "        )\n",
    "        error = cv2.norm(imgpoints[cam][i], imgpoints_proj, cv2.NORM_L2) / len(\n",
    "            imgpoints_proj\n",
    "        )\n",
    "        mean_error += error\n",
    "    print(\n",
    "        \"Mean re-projection error for %s images: %.3f pixels \"\n",
    "        % (cam, mean_error / len(objpoints[cam]))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing stereo calibration for \n",
      "Saving the stereo parameters for every pair of cameras as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\camera_matrix\n",
      "Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\n"
     ]
    }
   ],
   "source": [
    "# Compute stereo calibration for each pair of cameras\n",
    "camera_pair = [[cam_names[0], cam_names[1]]]\n",
    "for pair in camera_pair:\n",
    "    print(\"Computing stereo calibration for \" % pair)\n",
    "    (\n",
    "        retval,\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        R,\n",
    "        T,\n",
    "        E,\n",
    "        F,\n",
    "    ) = cv2.stereoCalibrate(\n",
    "        objpoints[pair[0]],\n",
    "        imgpoints[pair[0]],\n",
    "        imgpoints[pair[1]],\n",
    "        dist_pickle[pair[0]][\"mtx\"],\n",
    "        dist_pickle[pair[0]][\"dist\"],\n",
    "        dist_pickle[pair[1]][\"mtx\"],\n",
    "        dist_pickle[pair[1]][\"dist\"],\n",
    "        (h, w),\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC,\n",
    "    )\n",
    "\n",
    "    # Stereo Rectification\n",
    "    rectify_scale = alpha  # Free scaling parameter check this https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-stereorectify\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        (h, w),\n",
    "        R,\n",
    "        T,\n",
    "        alpha=rectify_scale,\n",
    "    )\n",
    "\n",
    "    stereo_params[pair[0] + \"-\" + pair[1]] = {\n",
    "        \"cameraMatrix1\": cameraMatrix1,\n",
    "        \"cameraMatrix2\": cameraMatrix2,\n",
    "        \"distCoeffs1\": distCoeffs1,\n",
    "        \"distCoeffs2\": distCoeffs2,\n",
    "        \"R\": R,\n",
    "        \"T\": T,\n",
    "        \"E\": E,\n",
    "        \"F\": F,\n",
    "        \"R1\": R1,\n",
    "        \"R2\": R2,\n",
    "        \"P1\": P1,\n",
    "        \"P2\": P2,\n",
    "        \"roi1\": roi1,\n",
    "        \"roi2\": roi2,\n",
    "        \"Q\": Q,\n",
    "        \"image_shape\": [img_shape[pair[0]], img_shape[pair[1]]],\n",
    "    }\n",
    "\n",
    "print(\n",
    "    \"Saving the stereo parameters for every pair of cameras as a pickle file in %s\"\n",
    "    % str(os.path.join(path_camera_matrix))\n",
    ")\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_pickle(\n",
    "    os.path.join(path_camera_matrix, \"stereo_params.pickle\"), stereo_params\n",
    ")\n",
    "print(\n",
    "    \"Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.13770670e+03, 0.00000000e+00, 1.27978779e+03],\n",
       "       [0.00000000e+00, 5.73144267e+03, 5.20461469e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameraMatrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check undistortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work, but the triangulation does. Just skip to the triangulation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images are undistorted and stored in D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\undistortion\n",
      "Use the function ``triangulate`` to undistort the dataframes and compute the triangulation\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_undistortion(config_path_3d, cbrow=cbrow, cbcol=cbcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pair = [[cam_names[0], cam_names[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_undistort = os.path.join(base_path, 'undistortion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairname = camera_pair[0][0] + \"-\" + camera_pair[0][1]\n",
    "map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "    stereo_params[pairname][\"cameraMatrix2\"],\n",
    "    stereo_params[pairname][\"distCoeffs2\"],\n",
    "    stereo_params[pairname][\"R2\"],\n",
    "    stereo_params[pairname][\"P2\"],\n",
    "    (stereo_params[pairname][\"image_shape\"][1]),\n",
    "    cv2.CV_16SC2,\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]]], dtype=int16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map2_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TYTELL~1\\AppData\\Local\\Temp/ipykernel_17764/2808552771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mgray1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 _, corners1 = cv2.findChessboardCorners(gray1, (cbcol, cbrow),  cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n\u001b[0m\u001b[0;32m     28\u001b[0m             cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pair in camera_pair:\n",
    "        map1_x, map1_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P1\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][0]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P2\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][1]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        cam1_undistort = []\n",
    "        cam2_undistort = []\n",
    "\n",
    "        for camnum, (cam, camfiles1, rot1) in enumerate(zip(cam_names, filenames, rotategrid)):\n",
    "            for fname in camfiles1:\n",
    "                _, filename = os.path.split(fname)\n",
    "                img1 = cv2.imread(fname)\n",
    "                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "                h, w = img1.shape[:2]\n",
    "                _, corners1 = cv2.findChessboardCorners(gray1, (cbcol, cbrow),  cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "                \n",
    "                if rot1:\n",
    "                    corners1 = corners1.reshape((cbrow,cbcol, -1))\n",
    "                    corners1 = corners1.transpose((1, 0, 2))\n",
    "                    corners1 = corners1.reshape((cbrow*cbcol, 1, -1))\n",
    "\n",
    "                corners_origin1 = cv2.cornerSubPix(\n",
    "                    gray1, corners1, (11, 11), (-1, -1), criteria\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Remapping dataFrame_camera1_undistort\n",
    "                im_remapped1 = cv2.remap(gray1, map1_x, map1_y, cv2.INTER_LANCZOS4)\n",
    "                imgpoints_proj_undistort = cv2.undistortPoints(\n",
    "                    src=corners_origin1,\n",
    "                    cameraMatrix=stereo_params[pair[0] + \"-\" + pair[1]][\n",
    "                        \"cameraMatrix{}\".format(camnum+1)\n",
    "                    ],\n",
    "                    distCoeffs=stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs{}\".format(camnum+1)],\n",
    "                    P=stereo_params[pair[0] + \"-\" + pair[1]][\"P{}\".format(camnum+1)],\n",
    "                    R=stereo_params[pair[0] + \"-\" + pair[1]][\"R{}\".format(camnum+1)],\n",
    "                )\n",
    "                cam1_undistort.append(imgpoints_proj_undistort)\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(str(path_undistort), filename + \"_undistort.jpg\"),\n",
    "                    im_remapped1,\n",
    "                )\n",
    "                imgpoints_proj_undistort = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        cam1_undistort = np.array(cam1_undistort)\n",
    "        cam2_undistort = np.array(cam2_undistort)\n",
    "        print(\"All images are undistorted and stored in %s\" % str(path_undistort))\n",
    "        print(\n",
    "            \"Use the function ``triangulate`` to undistort the dataframes and compute the triangulation\"\n",
    "        )\n",
    "\n",
    "        if plot == True:\n",
    "            f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f1.suptitle(\n",
    "                str(\"Original Image: Views from \" + pair[0] + \" and \" + pair[1]),\n",
    "                fontsize=25,\n",
    "            )\n",
    "\n",
    "            # Display images in RGB\n",
    "            ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            norm = mcolors.Normalize(vmin=0.0, vmax=cam1_undistort.shape[1])\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"Original_Image.png\"))\n",
    "\n",
    "            # Plot the undistorted corner points\n",
    "            f2, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f2.suptitle(\n",
    "                \"Undistorted corner points on camera-1 and camera-2\", fontsize=25\n",
    "            )\n",
    "            ax1.imshow(cv2.cvtColor(im_remapped1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(im_remapped2, cv2.COLOR_BGR2RGB))\n",
    "            for i in range(0, cam1_undistort.shape[1]):\n",
    "                ax1.scatter(\n",
    "                    [cam1_undistort[-1][i, 0, 0]],\n",
    "                    [cam1_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "                ax2.scatter(\n",
    "                    [cam2_undistort[-1][i, 0, 0]],\n",
    "                    [cam2_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"undistorted_points.png\"))\n",
    "\n",
    "            # Triangulate\n",
    "            triangulate = auxiliaryfunctions_3d.compute_triangulation_calibration_images(\n",
    "                stereo_params[pair[0] + \"-\" + pair[1]],\n",
    "                cam1_undistort,\n",
    "                cam2_undistort,\n",
    "                path_undistort,\n",
    "                cfg_3d,\n",
    "                plot=True,\n",
    "            )\n",
    "            auxiliaryfunctions.write_pickle(\"triangulate.pickle\", triangulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of pairs: [['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial01_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial02_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial02_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial05_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial05_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial06_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial06_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial07_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial07_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial08_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial08_lateral.mp4']]\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial01_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial01_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial01_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial01_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial02_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial02_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial02_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial02_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial05_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial05_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial05_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial05_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial06_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial06_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial06_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial06_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial07_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial07_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial07_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial07_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial08_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial08_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\20211029_ms05_trial08_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211029_ms05_trial08_lateral\n",
      "This file is already analyzed!\n",
      "All videos were analyzed...\n",
      "Now you can create 3D video(s) using deeplabcut.create_labeled_video_3d\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.triangulate(config_path_3d, r'D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos',\n",
    "                    videotype='.mp4', save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial01_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial01_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial02_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial02_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial02_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial05_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial05_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial05_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial06_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial06_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial06_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial07_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial07_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial07_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial08_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial08_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-03-17-3d\\\\videos\\\\20211029_ms05_trial08_lateral.mp4']]\n",
      "Video already created...\n",
      "Video already created...\n",
      "Video already created...\n",
      "Video already created...\n",
      "Creating 3D video from 20211029_ms05_trial07_rear.mp4 and 20211029_ms05_trial07_lateral.mp4 using 20211029_ms05_trial07_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\*20211029_ms05_trial07_rearDLC_resnet50_UpAndDownRearNov27shuffle1_1030000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\*20211029_ms05_trial07_lateralDLC_resnet50_UpAndDownLateral2Feb7shuffle1_1030000*filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:19<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3D video from 20211029_ms05_trial08_rear.mp4 and 20211029_ms05_trial08_lateral.mp4 using 20211029_ms05_trial08_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\*20211029_ms05_trial08_rearDLC_resnet50_UpAndDownRearNov27shuffle1_1030000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos\\*20211029_ms05_trial08_lateralDLC_resnet50_UpAndDownLateral2Feb7shuffle1_1030000*filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:13<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video_3d(config_path_3d, [r'D:\\UpAndDown\\UpAndDown-Ming-2022-03-17-3d\\videos'],\n",
    "                 videotype='.mp4',\n",
    "                 start=100, end=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "39d53beb224696930fcccd093403b624330f7e52536f84b9af550c8c3c9f35f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
