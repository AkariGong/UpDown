{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.1.1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\__init__.py:81: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import deeplabcut\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calibration file: 20220728_checkerboard_cal02**\n",
    "\n",
    "**trials: 20220728 ms06 trial 01-19 (all trials)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the 3D DeepLabCut project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the base path for each different 3D project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new 3d project!\n",
      "Created \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\camera_matrix\"\n",
      "Created \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\calibration_images\"\n",
      "Created \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\undistortion\"\n",
      "Created \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\corners\"\n",
      "Created \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\removed_calibration_images\"\n",
      "Generated \"D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\config.yaml\"\n",
      "\n",
      "A new project with name UpAndDown-Ming-2023-03-25-3d is created at D:\\UpAndDown and a configurable file (config.yaml) is stored there. If you have not calibrated the cameras, then use the function 'calibrate_camera' to start calibrating the camera otherwise use the function ``triangulate`` to triangulate the dataframe\n"
     ]
    }
   ],
   "source": [
    "config_path_3d = os.path.join(base_path, 'config.yaml')\n",
    "\n",
    "if os.path.exists(config_path_3d):\n",
    "    print('Found existing 3d project')\n",
    "else:\n",
    "    print('Create new 3d project!')\n",
    "    deeplabcut.create_new_project_3d('UpAndDown','Ming', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you edit the 3D config.yaml file. The cameras should be named 'rear' and 'lateral', and the config file paths for the 2D tracking should be updated correctly. Also update the skeleton to match the 2D tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/Overviewof3D.md for an overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code below is modified from the DLC repository here: https://github.com/DeepLabCut/DeepLabCut/blob/master/deeplabcut/pose_estimation_3d/camera_calibration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of internal corners on our checkboard. (e.g., 8x8 squares has 7x7 internal corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbrow = 9\n",
    "cbcol = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_names = ['rear', 'lateral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\calibration_images\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\corners\n"
     ]
    }
   ],
   "source": [
    "framedir = os.path.join(base_path, 'calibration_images')\n",
    "print(framedir)\n",
    "cornerdir = os.path.join(base_path, 'corners')\n",
    "print(cornerdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\rear-001.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\rear-002.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\rear-003.jpg']\n",
      " ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\lateral-001.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\lateral-002.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\calibration_images\\\\lateral-003.jpg']]\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for cam1 in cam_names:\n",
    "    fn1 = glob.glob(os.path.join(framedir, cam1 + '*.jpg'))\n",
    "    fn1.sort()\n",
    "    filenames.append(fn1)\n",
    "\n",
    "filenames = np.array(filenames)\n",
    "\n",
    "print(filenames[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_name(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name_list = []\n",
    "    for i in range(len(file_list)):\n",
    "        file_name = path + '/' + file_list[i]\n",
    "        file_name_list.append(file_name)\n",
    "    return file_name_list\n",
    "\n",
    "def files_name(path):\n",
    "    filesname_list = []\n",
    "    for i in range(len(path)):\n",
    "        (filepath, tempfilename) = os.path.split(path[i])\n",
    "        (filesname, extension) = os.path.splitext(tempfilename)\n",
    "        filesname_list.append(filesname)\n",
    "    print(filesname_list)\n",
    "    return filesname_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = dir_name(framedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lateral-001', 'lateral-002', 'lateral-003', 'lateral-004', 'lateral-005', 'lateral-006', 'lateral-007', 'lateral-008', 'lateral-009', 'lateral-010', 'lateral-011', 'lateral-012', 'lateral-013', 'lateral-014', 'lateral-015', 'lateral-016', 'lateral-017', 'lateral-018', 'lateral-019', 'lateral-020', 'lateral-021', 'lateral-022', 'lateral-023', 'lateral-024', 'lateral-025', 'lateral-026', 'lateral-027', 'lateral-028', 'lateral-029', 'lateral-030', 'lateral-031', 'lateral-032', 'lateral-033', 'lateral-034', 'lateral-035', 'lateral-036', 'lateral-037', 'lateral-038', 'lateral-039', 'lateral-040', 'lateral-041', 'lateral-042', 'lateral-043', 'lateral-044', 'lateral-045', 'lateral-046', 'lateral-047', 'lateral-048', 'lateral-049', 'lateral-050', 'lateral-051', 'lateral-052', 'lateral-053', 'lateral-054', 'lateral-055', 'lateral-056', 'lateral-057', 'rear-001', 'rear-002', 'rear-003', 'rear-004', 'rear-005', 'rear-006', 'rear-007', 'rear-008', 'rear-009', 'rear-010', 'rear-011', 'rear-012', 'rear-013', 'rear-014', 'rear-015', 'rear-016', 'rear-017', 'rear-018', 'rear-019', 'rear-020', 'rear-021', 'rear-022', 'rear-023', 'rear-024', 'rear-025', 'rear-026', 'rear-027', 'rear-028', 'rear-029', 'rear-030', 'rear-031', 'rear-032', 'rear-033', 'rear-034', 'rear-035', 'rear-036', 'rear-037', 'rear-038', 'rear-039', 'rear-040', 'rear-041', 'rear-042', 'rear-043', 'rear-044', 'rear-045', 'rear-046', 'rear-047', 'rear-048', 'rear-049', 'rear-050', 'rear-051', 'rear-052', 'rear-053', 'rear-054', 'rear-055', 'rear-056', 'rear-057']\n",
      "{'lateral-001': {'fliplr': True, 'rotate': 0}, 'lateral-002': {'fliplr': True, 'rotate': 0}, 'lateral-003': {'fliplr': True, 'rotate': 0}, 'lateral-004': {'fliplr': True, 'rotate': 0}, 'lateral-005': {'fliplr': True, 'rotate': 0}, 'lateral-006': {'fliplr': True, 'rotate': 0}, 'lateral-007': {'fliplr': True, 'rotate': 0}, 'lateral-008': {'fliplr': True, 'rotate': 0}, 'lateral-009': {'fliplr': True, 'rotate': 0}, 'lateral-010': {'fliplr': True, 'rotate': 0}, 'lateral-011': {'fliplr': True, 'rotate': 0}, 'lateral-012': {'fliplr': True, 'rotate': 0}, 'lateral-013': {'fliplr': True, 'rotate': 0}, 'lateral-014': {'fliplr': True, 'rotate': 0}, 'lateral-015': {'fliplr': True, 'rotate': 0}, 'lateral-016': {'fliplr': True, 'rotate': 0}, 'lateral-017': {'fliplr': True, 'rotate': 0}, 'lateral-018': {'fliplr': True, 'rotate': 0}, 'lateral-019': {'fliplr': True, 'rotate': 0}, 'lateral-020': {'fliplr': True, 'rotate': 0}, 'lateral-021': {'fliplr': True, 'rotate': 0}, 'lateral-022': {'fliplr': True, 'rotate': 0}, 'lateral-023': {'fliplr': True, 'rotate': 0}, 'lateral-024': {'fliplr': True, 'rotate': 0}, 'lateral-025': {'fliplr': True, 'rotate': 0}, 'lateral-026': {'fliplr': True, 'rotate': 0}, 'lateral-027': {'fliplr': True, 'rotate': 0}, 'lateral-028': {'fliplr': True, 'rotate': 0}, 'lateral-029': {'fliplr': True, 'rotate': 0}, 'lateral-030': {'fliplr': True, 'rotate': 0}, 'lateral-031': {'fliplr': True, 'rotate': 0}, 'lateral-032': {'fliplr': True, 'rotate': 0}, 'lateral-033': {'fliplr': True, 'rotate': 0}, 'lateral-034': {'fliplr': True, 'rotate': 0}, 'lateral-035': {'fliplr': True, 'rotate': 0}, 'lateral-036': {'fliplr': True, 'rotate': 0}, 'lateral-037': {'fliplr': True, 'rotate': 0}, 'lateral-038': {'fliplr': True, 'rotate': 0}, 'lateral-039': {'fliplr': True, 'rotate': 0}, 'lateral-040': {'fliplr': True, 'rotate': 0}, 'lateral-041': {'fliplr': True, 'rotate': 0}, 'lateral-042': {'fliplr': True, 'rotate': 0}, 'lateral-043': {'fliplr': True, 'rotate': 0}, 'lateral-044': {'fliplr': True, 'rotate': 0}, 'lateral-045': {'fliplr': True, 'rotate': 0}, 'lateral-046': {'fliplr': True, 'rotate': 0}, 'lateral-047': {'fliplr': True, 'rotate': 0}, 'lateral-048': {'fliplr': True, 'rotate': 0}, 'lateral-049': {'fliplr': True, 'rotate': 0}, 'lateral-050': {'fliplr': True, 'rotate': 0}, 'lateral-051': {'fliplr': True, 'rotate': 0}, 'lateral-052': {'fliplr': True, 'rotate': 0}, 'lateral-053': {'fliplr': True, 'rotate': 0}, 'lateral-054': {'fliplr': True, 'rotate': 0}, 'lateral-055': {'fliplr': True, 'rotate': 0}, 'lateral-056': {'fliplr': True, 'rotate': 0}, 'lateral-057': {'fliplr': True, 'rotate': 0}, 'rear-001': {'fliplr': False, 'rotate': 0}, 'rear-002': {'fliplr': False, 'rotate': 0}, 'rear-003': {'fliplr': False, 'rotate': 0}, 'rear-004': {'fliplr': False, 'rotate': 0}, 'rear-005': {'fliplr': False, 'rotate': 0}, 'rear-006': {'fliplr': False, 'rotate': 0}, 'rear-007': {'fliplr': False, 'rotate': 0}, 'rear-008': {'fliplr': False, 'rotate': 0}, 'rear-009': {'fliplr': False, 'rotate': 0}, 'rear-010': {'fliplr': False, 'rotate': 0}, 'rear-011': {'fliplr': False, 'rotate': 0}, 'rear-012': {'fliplr': False, 'rotate': 0}, 'rear-013': {'fliplr': False, 'rotate': 0}, 'rear-014': {'fliplr': False, 'rotate': 0}, 'rear-015': {'fliplr': False, 'rotate': 0}, 'rear-016': {'fliplr': False, 'rotate': 0}, 'rear-017': {'fliplr': False, 'rotate': 0}, 'rear-018': {'fliplr': False, 'rotate': 0}, 'rear-019': {'fliplr': False, 'rotate': 0}, 'rear-020': {'fliplr': False, 'rotate': 0}, 'rear-021': {'fliplr': False, 'rotate': 0}, 'rear-022': {'fliplr': False, 'rotate': 0}, 'rear-023': {'fliplr': False, 'rotate': 0}, 'rear-024': {'fliplr': False, 'rotate': 0}, 'rear-025': {'fliplr': False, 'rotate': 0}, 'rear-026': {'fliplr': False, 'rotate': 0}, 'rear-027': {'fliplr': False, 'rotate': 0}, 'rear-028': {'fliplr': False, 'rotate': 0}, 'rear-029': {'fliplr': False, 'rotate': 0}, 'rear-030': {'fliplr': False, 'rotate': 0}, 'rear-031': {'fliplr': False, 'rotate': 0}, 'rear-032': {'fliplr': False, 'rotate': 0}, 'rear-033': {'fliplr': False, 'rotate': 0}, 'rear-034': {'fliplr': False, 'rotate': 0}, 'rear-035': {'fliplr': False, 'rotate': 0}, 'rear-036': {'fliplr': False, 'rotate': 0}, 'rear-037': {'fliplr': False, 'rotate': 0}, 'rear-038': {'fliplr': False, 'rotate': 0}, 'rear-039': {'fliplr': False, 'rotate': 0}, 'rear-040': {'fliplr': False, 'rotate': 0}, 'rear-041': {'fliplr': False, 'rotate': 0}, 'rear-042': {'fliplr': False, 'rotate': 0}, 'rear-043': {'fliplr': False, 'rotate': 0}, 'rear-044': {'fliplr': False, 'rotate': 0}, 'rear-045': {'fliplr': False, 'rotate': 0}, 'rear-046': {'fliplr': False, 'rotate': 0}, 'rear-047': {'fliplr': False, 'rotate': 0}, 'rear-048': {'fliplr': False, 'rotate': 0}, 'rear-049': {'fliplr': False, 'rotate': 0}, 'rear-050': {'fliplr': False, 'rotate': 0}, 'rear-051': {'fliplr': False, 'rotate': 0}, 'rear-052': {'fliplr': False, 'rotate': 0}, 'rear-053': {'fliplr': False, 'rotate': 0}, 'rear-054': {'fliplr': False, 'rotate': 0}, 'rear-055': {'fliplr': False, 'rotate': 0}, 'rear-056': {'fliplr': False, 'rotate': 0}, 'rear-057': {'fliplr': False, 'rotate': 0}}\n"
     ]
    }
   ],
   "source": [
    "rotategrid = {}\n",
    "keys = files_name(files_path)\n",
    "values = [{'fliplr': True, 'rotate': 0},\n",
    "          {'fliplr': False, 'rotate': 0}]\n",
    "\n",
    "for i in keys:\n",
    "        if i.startswith('lateral'):\n",
    "                rotategrid[i] = values[0]\n",
    "                \n",
    "        else:\n",
    "                rotategrid[i] = values[1]\n",
    "\n",
    "print(rotategrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((cbrow * cbcol, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:cbcol, 0:cbrow].T.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rear-001\n",
      "Found checkboard corners!\n",
      "rear-002\n",
      "Found checkboard corners!\n",
      "rear-003\n",
      "Found checkboard corners!\n",
      "rear-004\n",
      "Found checkboard corners!\n",
      "rear-005\n",
      "Found checkboard corners!\n",
      "rear-006\n",
      "Found checkboard corners!\n",
      "rear-007\n",
      "Found checkboard corners!\n",
      "rear-008\n",
      "Found checkboard corners!\n",
      "rear-009\n",
      "Found checkboard corners!\n",
      "rear-010\n",
      "Found checkboard corners!\n",
      "rear-011\n",
      "Found checkboard corners!\n",
      "rear-012\n",
      "Found checkboard corners!\n",
      "rear-013\n",
      "Found checkboard corners!\n",
      "rear-014\n",
      "Found checkboard corners!\n",
      "rear-015\n",
      "Found checkboard corners!\n",
      "rear-016\n",
      "Found checkboard corners!\n",
      "rear-017\n",
      "Found checkboard corners!\n",
      "rear-018\n",
      "Found checkboard corners!\n",
      "rear-019\n",
      "Found checkboard corners!\n",
      "rear-020\n",
      "Found checkboard corners!\n",
      "rear-021\n",
      "Found checkboard corners!\n",
      "rear-022\n",
      "Found checkboard corners!\n",
      "rear-023\n",
      "Found checkboard corners!\n",
      "rear-024\n",
      "Found checkboard corners!\n",
      "rear-025\n",
      "Found checkboard corners!\n",
      "rear-026\n",
      "Found checkboard corners!\n",
      "rear-027\n",
      "Found checkboard corners!\n",
      "rear-028\n",
      "Found checkboard corners!\n",
      "rear-029\n",
      "Found checkboard corners!\n",
      "rear-030\n",
      "Found checkboard corners!\n",
      "rear-031\n",
      "Found checkboard corners!\n",
      "rear-032\n",
      "Found checkboard corners!\n",
      "rear-033\n",
      "Found checkboard corners!\n",
      "rear-034\n",
      "Found checkboard corners!\n",
      "rear-035\n",
      "Found checkboard corners!\n",
      "rear-036\n",
      "Found checkboard corners!\n",
      "rear-037\n",
      "Found checkboard corners!\n",
      "rear-038\n",
      "Found checkboard corners!\n",
      "rear-039\n",
      "Found checkboard corners!\n",
      "rear-040\n",
      "Found checkboard corners!\n",
      "rear-041\n",
      "Found checkboard corners!\n",
      "rear-042\n",
      "Found checkboard corners!\n",
      "rear-043\n",
      "Found checkboard corners!\n",
      "rear-044\n",
      "Found checkboard corners!\n",
      "rear-045\n",
      "Found checkboard corners!\n",
      "rear-046\n",
      "Found checkboard corners!\n",
      "rear-047\n",
      "Found checkboard corners!\n",
      "rear-048\n",
      "Found checkboard corners!\n",
      "rear-049\n",
      "Found checkboard corners!\n",
      "rear-050\n",
      "Found checkboard corners!\n",
      "rear-051\n",
      "Found checkboard corners!\n",
      "rear-052\n",
      "Found checkboard corners!\n",
      "rear-053\n",
      "Found checkboard corners!\n",
      "rear-054\n",
      "Found checkboard corners!\n",
      "rear-055\n",
      "Found checkboard corners!\n",
      "rear-056\n",
      "Found checkboard corners!\n",
      "rear-057\n",
      "Found checkboard corners!\n",
      "lateral-001\n",
      "Found checkboard corners!\n",
      "lateral-002\n",
      "Found checkboard corners!\n",
      "lateral-003\n",
      "Found checkboard corners!\n",
      "lateral-004\n",
      "Found checkboard corners!\n",
      "lateral-005\n",
      "Found checkboard corners!\n",
      "lateral-006\n",
      "Found checkboard corners!\n",
      "lateral-007\n",
      "Found checkboard corners!\n",
      "lateral-008\n",
      "Found checkboard corners!\n",
      "lateral-009\n",
      "Found checkboard corners!\n",
      "lateral-010\n",
      "Found checkboard corners!\n",
      "lateral-011\n",
      "Found checkboard corners!\n",
      "lateral-012\n",
      "Found checkboard corners!\n",
      "lateral-013\n",
      "Found checkboard corners!\n",
      "lateral-014\n",
      "Found checkboard corners!\n",
      "lateral-015\n",
      "Found checkboard corners!\n",
      "lateral-016\n",
      "Found checkboard corners!\n",
      "lateral-017\n",
      "Found checkboard corners!\n",
      "lateral-018\n",
      "Found checkboard corners!\n",
      "lateral-019\n",
      "Found checkboard corners!\n",
      "lateral-020\n",
      "Found checkboard corners!\n",
      "lateral-021\n",
      "Found checkboard corners!\n",
      "lateral-022\n",
      "Found checkboard corners!\n",
      "lateral-023\n",
      "Found checkboard corners!\n",
      "lateral-024\n",
      "Found checkboard corners!\n",
      "lateral-025\n",
      "Found checkboard corners!\n",
      "lateral-026\n",
      "Found checkboard corners!\n",
      "lateral-027\n",
      "Found checkboard corners!\n",
      "lateral-028\n",
      "Found checkboard corners!\n",
      "lateral-029\n",
      "Found checkboard corners!\n",
      "lateral-030\n",
      "Found checkboard corners!\n",
      "lateral-031\n",
      "Found checkboard corners!\n",
      "lateral-032\n",
      "Found checkboard corners!\n",
      "lateral-033\n",
      "Found checkboard corners!\n",
      "lateral-034\n",
      "Found checkboard corners!\n",
      "lateral-035\n",
      "Found checkboard corners!\n",
      "lateral-036\n",
      "Found checkboard corners!\n",
      "lateral-037\n",
      "Found checkboard corners!\n",
      "lateral-038\n",
      "Found checkboard corners!\n",
      "lateral-039\n",
      "Found checkboard corners!\n",
      "lateral-040\n",
      "Found checkboard corners!\n",
      "lateral-041\n",
      "Found checkboard corners!\n",
      "lateral-042\n",
      "Found checkboard corners!\n",
      "lateral-043\n",
      "Found checkboard corners!\n",
      "lateral-044\n",
      "Found checkboard corners!\n",
      "lateral-045\n",
      "Found checkboard corners!\n",
      "lateral-046\n",
      "Found checkboard corners!\n",
      "lateral-047\n",
      "Found checkboard corners!\n",
      "lateral-048\n",
      "Found checkboard corners!\n",
      "lateral-049\n",
      "Found checkboard corners!\n",
      "lateral-050\n",
      "Found checkboard corners!\n",
      "lateral-051\n",
      "Found checkboard corners!\n",
      "lateral-052\n",
      "Found checkboard corners!\n",
      "lateral-053\n",
      "Found checkboard corners!\n",
      "lateral-054\n",
      "Found checkboard corners!\n",
      "lateral-055\n",
      "Found checkboard corners!\n",
      "lateral-056\n",
      "Found checkboard corners!\n",
      "lateral-057\n",
      "Found checkboard corners!\n"
     ]
    }
   ],
   "source": [
    "img_shape = {}\n",
    "objpoints = {}  # 3d point in real world space\n",
    "imgpoints = {}  # 2d points in image plane.\n",
    "dist_pickle = {}\n",
    "stereo_params = {}\n",
    "for cam in cam_names:\n",
    "    objpoints.setdefault(cam, [])\n",
    "    imgpoints.setdefault(cam, [])\n",
    "    dist_pickle.setdefault(cam, [])\n",
    "\n",
    "for cam, camfiles1 in zip(cam_names, filenames):\n",
    "    for fn1 in camfiles1:\n",
    "        img = cv2.imread(fn1)  # read in an image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert the color of an image \n",
    " \n",
    "        pn, fn = os.path.split(fn1)\n",
    "        fn, ext = os.path.splitext(fn)\n",
    "\n",
    "        print('{}'.format(fn))\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (cbcol,cbrow), cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "\n",
    "        if ret:\n",
    "            print('Found checkboard corners!')\n",
    "\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "            if fn in rotategrid:\n",
    "                # corners = corners.reshape((cbcol,cbrow, -1))  # divide into cbcol matrices, each has cbrow rows and 1 col.\n",
    "                corners = corners.reshape((cbrow,cbcol, -1))\n",
    "\n",
    "                if 'fliplr' in rotategrid[fn] and \\\n",
    "                    rotategrid[fn]['fliplr']:\n",
    "                    corners = np.flip(corners, axis=1)\n",
    "                    # corners = np.fliplr(corners)\n",
    "                \n",
    "                if 'rotate' in rotategrid[fn]:\n",
    "                    r = rotategrid[fn]['rotate']\n",
    "\n",
    "                    if r == 90:\n",
    "                        k = 1\n",
    "                    elif r == -90:\n",
    "                        k = -1\n",
    "                    elif r == 180:\n",
    "                        k = 2\n",
    "                    else:\n",
    "                        k = 0\n",
    "\n",
    "                    corners = np.rot90(corners, k, axes=(0, 1))\n",
    "\n",
    "                corners = corners.reshape(cbrow*cbcol, 1, -1)\n",
    "            \n",
    "            img_shape[cam] = gray.shape[::-1]\n",
    "            objpoints[cam].append(objp)\n",
    "            imgpoints[cam].append(corners)            \n",
    "        else:\n",
    "            print('Not found')\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (cbcol,cbrow), corners, ret)\n",
    "\n",
    "        cv2.imwrite(os.path.join(cornerdir, fn + '_corner.jpg'), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_camera_matrix = os.path.join(base_path,'camera_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intrinsic camera calibration matrices for rear as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\camera_matrix\n",
      "Mean re-projection error for rear images: 0.087 pixels \n",
      "Saving intrinsic camera calibration matrices for lateral as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\camera_matrix\n",
      "Mean re-projection error for lateral images: 0.028 pixels \n"
     ]
    }
   ],
   "source": [
    "for cam in cam_names:\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints[cam], imgpoints[cam], img_shape[cam], None, None\n",
    "    )\n",
    "\n",
    "    # Save the camera calibration result for later use (we won't use rvecs / tvecs)\n",
    "    dist_pickle[cam] = {\n",
    "        \"mtx\": mtx,\n",
    "        \"dist\": dist,\n",
    "        \"objpoints\": objpoints[cam],\n",
    "        \"imgpoints\": imgpoints[cam],\n",
    "    }\n",
    "    pickle.dump(\n",
    "        dist_pickle,\n",
    "        open(\n",
    "            os.path.join(path_camera_matrix, cam + \"_intrinsic_params.pickle\"),\n",
    "            \"wb\",\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"Saving intrinsic camera calibration matrices for %s as a pickle file in %s\"\n",
    "        % (cam, os.path.join(path_camera_matrix))\n",
    "    )\n",
    "\n",
    "    # Compute mean re-projection errors for individual cameras\n",
    "    mean_error = 0\n",
    "    for i in range(len(objpoints[cam])):\n",
    "        imgpoints_proj, _ = cv2.projectPoints(\n",
    "            objpoints[cam][i], rvecs[i], tvecs[i], mtx, dist\n",
    "        )\n",
    "        error = cv2.norm(imgpoints[cam][i], imgpoints_proj, cv2.NORM_L2) / len(\n",
    "            imgpoints_proj\n",
    "        )\n",
    "        mean_error += error\n",
    "    print(\n",
    "        \"Mean re-projection error for %s images: %.3f pixels \"\n",
    "        % (cam, mean_error / len(objpoints[cam]))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104 2560\n"
     ]
    }
   ],
   "source": [
    "# print(img.shape[:2])\n",
    "h, w = img.shape[:2]\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing stereo calibration for \n",
      "Saving the stereo parameters for every pair of cameras as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\camera_matrix\n",
      "Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\n"
     ]
    }
   ],
   "source": [
    "# Compute stereo calibration for each pair of cameras\n",
    "camera_pair = [[cam_names[0], cam_names[1]]]\n",
    "for pair in camera_pair:\n",
    "    print(\"Computing stereo calibration for \" % pair)\n",
    "    (\n",
    "        retval,\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        R,\n",
    "        T,\n",
    "        E,\n",
    "        F,\n",
    "    ) = cv2.stereoCalibrate(\n",
    "        objpoints[pair[0]],\n",
    "        imgpoints[pair[0]],\n",
    "        imgpoints[pair[1]],\n",
    "        dist_pickle[pair[0]][\"mtx\"],\n",
    "        dist_pickle[pair[0]][\"dist\"],\n",
    "        dist_pickle[pair[1]][\"mtx\"],\n",
    "        dist_pickle[pair[1]][\"dist\"],\n",
    "        (h, w),\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC,\n",
    "    )\n",
    "\n",
    "    # Stereo Rectification\n",
    "    rectify_scale = alpha  # Free scaling parameter check this https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-stereorectify\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        (h, w),\n",
    "        R,\n",
    "        T,\n",
    "        alpha=rectify_scale,\n",
    "    )\n",
    "\n",
    "    stereo_params[pair[0] + \"-\" + pair[1]] = {\n",
    "        \"cameraMatrix1\": cameraMatrix1,\n",
    "        \"cameraMatrix2\": cameraMatrix2,\n",
    "        \"distCoeffs1\": distCoeffs1,\n",
    "        \"distCoeffs2\": distCoeffs2,\n",
    "        \"R\": R,\n",
    "        \"T\": T,\n",
    "        \"E\": E,\n",
    "        \"F\": F,\n",
    "        \"R1\": R1,\n",
    "        \"R2\": R2,\n",
    "        \"P1\": P1,\n",
    "        \"P2\": P2,\n",
    "        \"roi1\": roi1,\n",
    "        \"roi2\": roi2,\n",
    "        \"Q\": Q,\n",
    "        \"image_shape\": [img_shape[pair[0]], img_shape[pair[1]]],\n",
    "    }\n",
    "\n",
    "print(\n",
    "    \"Saving the stereo parameters for every pair of cameras as a pickle file in %s\"\n",
    "    % str(os.path.join(path_camera_matrix))\n",
    ")\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_pickle(\n",
    "    os.path.join(path_camera_matrix, \"stereo_params.pickle\"), stereo_params\n",
    ")\n",
    "print(\n",
    "    \"Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.25831837e+03, 0.00000000e+00, 1.25457316e+03],\n",
       "       [0.00000000e+00, 5.05284664e+03, 5.54125472e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameraMatrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check undistortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work, but the triangulation does. Just skip to the triangulation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_undistortion(config_path_3d, cbrow=cbrow, cbcol=cbcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pair = [[cam_names[0], cam_names[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_undistort = os.path.join(base_path, 'undistortion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairname = camera_pair[0][0] + \"-\" + camera_pair[0][1]\n",
    "map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "    stereo_params[pairname][\"cameraMatrix2\"],\n",
    "    stereo_params[pairname][\"distCoeffs2\"],\n",
    "    stereo_params[pairname][\"R2\"],\n",
    "    stereo_params[pairname][\"P2\"],\n",
    "    (stereo_params[pairname][\"image_shape\"][1]),\n",
    "    cv2.CV_16SC2,\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in camera_pair:\n",
    "        map1_x, map1_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P1\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][0]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P2\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][1]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        cam1_undistort = []\n",
    "        cam2_undistort = []\n",
    "\n",
    "        for camnum, (cam, camfiles1, rot1) in enumerate(zip(cam_names, filenames, rotategrid)):\n",
    "            for fname in camfiles1:\n",
    "                _, filename = os.path.split(fname)\n",
    "                img1 = cv2.imread(fname)\n",
    "                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "                h, w = img1.shape[:2]\n",
    "                _, corners1 = cv2.findChessboardCorners(gray1, (cbcol, cbrow),  cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "                \n",
    "                if rot1:\n",
    "                    corners1 = corners1.reshape((cbrow,cbcol, -1))\n",
    "                    corners1 = corners1.transpose((1, 0, 2))\n",
    "                    corners1 = corners1.reshape((cbrow*cbcol, 1, -1))\n",
    "\n",
    "                corners_origin1 = cv2.cornerSubPix(\n",
    "                    gray1, corners1, (11, 11), (-1, -1), criteria\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Remapping dataFrame_camera1_undistort\n",
    "                im_remapped1 = cv2.remap(gray1, map1_x, map1_y, cv2.INTER_LANCZOS4)\n",
    "                imgpoints_proj_undistort = cv2.undistortPoints(\n",
    "                    src=corners_origin1,\n",
    "                    cameraMatrix=stereo_params[pair[0] + \"-\" + pair[1]][\n",
    "                        \"cameraMatrix{}\".format(camnum+1)\n",
    "                    ],\n",
    "                    distCoeffs=stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs{}\".format(camnum+1)],\n",
    "                    P=stereo_params[pair[0] + \"-\" + pair[1]][\"P{}\".format(camnum+1)],\n",
    "                    R=stereo_params[pair[0] + \"-\" + pair[1]][\"R{}\".format(camnum+1)],\n",
    "                )\n",
    "                cam1_undistort.append(imgpoints_proj_undistort)\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(str(path_undistort), filename + \"_undistort.jpg\"),\n",
    "                    im_remapped1,\n",
    "                )\n",
    "                imgpoints_proj_undistort = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        cam1_undistort = np.array(cam1_undistort)\n",
    "        cam2_undistort = np.array(cam2_undistort)\n",
    "        print(\"All images are undistorted and stored in %s\" % str(path_undistort))\n",
    "        print(\n",
    "            \"Use the function ``triangulate`` to undistort the dataframes and compute the triangulation\"\n",
    "        )\n",
    "\n",
    "        if plot == True:\n",
    "            f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f1.suptitle(\n",
    "                str(\"Original Image: Views from \" + pair[0] + \" and \" + pair[1]),\n",
    "                fontsize=25,\n",
    "            )\n",
    "\n",
    "            # Display images in RGB\n",
    "            ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            norm = mcolors.Normalize(vmin=0.0, vmax=cam1_undistort.shape[1])\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"Original_Image.png\"))\n",
    "\n",
    "            # Plot the undistorted corner points\n",
    "            f2, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f2.suptitle(\n",
    "                \"Undistorted corner points on camera-1 and camera-2\", fontsize=25\n",
    "            )\n",
    "            ax1.imshow(cv2.cvtColor(im_remapped1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(im_remapped2, cv2.COLOR_BGR2RGB))\n",
    "            for i in range(0, cam1_undistort.shape[1]):\n",
    "                ax1.scatter(\n",
    "                    [cam1_undistort[-1][i, 0, 0]],\n",
    "                    [cam1_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "                ax2.scatter(\n",
    "                    [cam2_undistort[-1][i, 0, 0]],\n",
    "                    [cam2_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"undistorted_points.png\"))\n",
    "\n",
    "            # Triangulate\n",
    "            triangulate = auxiliaryfunctions_3d.compute_triangulation_calibration_images(\n",
    "                stereo_params[pair[0] + \"-\" + pair[1]],\n",
    "                cam1_undistort,\n",
    "                cam2_undistort,\n",
    "                path_undistort,\n",
    "                cfg_3d,\n",
    "                plot=True,\n",
    "            )\n",
    "            auxiliaryfunctions.write_pickle(\"triangulate.pickle\", triangulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of pairs: [['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial02_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial02_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial03_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial03_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial04_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial04_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial05_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial05_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial06_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial06_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial07_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial07_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial08_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial08_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial09_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial09_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial10_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial10_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial11_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial11_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial12_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial12_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial13_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial13_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial14_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial14_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial15_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial15_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial16_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial16_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial17_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial17_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial18_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial18_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial19_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial19_lateral.mp4']]\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial01_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_rear.mp4\n",
      "Data from 20220728_ms06_trial01_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial01_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial01_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_rear.mp4 using config_file_rear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_3d\\triangulation.py:332: UserWarning: The number of frames do not match in the two videos. Please make sure that your videos have same number of frames and then retry! Excluding the extra frames from the longer video.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial02_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_rear.mp4\n",
      "Data from 20220728_ms06_trial02_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial02_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial02_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial03_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_rear.mp4\n",
      "Data from 20220728_ms06_trial03_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial03_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial03_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial04_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_rear.mp4\n",
      "Data from 20220728_ms06_trial04_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial04_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial04_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial05_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_rear.mp4\n",
      "Data from 20220728_ms06_trial05_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial05_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial05_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_rear.mp4 using config_file_rear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_3d\\triangulation.py:332: UserWarning: The number of frames do not match in the two videos. Please make sure that your videos have same number of frames and then retry! Excluding the extra frames from the longer video.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial06_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_rear.mp4\n",
      "Data from 20220728_ms06_trial06_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial06_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial06_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial07_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_rear.mp4\n",
      "Data from 20220728_ms06_trial07_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial07_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial07_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial08_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_rear.mp4\n",
      "Data from 20220728_ms06_trial08_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial08_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial08_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial09_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_rear.mp4\n",
      "Data from 20220728_ms06_trial09_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial09_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial09_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial10_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_rear.mp4\n",
      "Data from 20220728_ms06_trial10_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial10_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial10_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial11_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_rear.mp4\n",
      "Data from 20220728_ms06_trial11_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial11_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial11_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial12_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_rear.mp4\n",
      "Data from 20220728_ms06_trial12_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial12_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial12_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial13_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_rear.mp4\n",
      "Data from 20220728_ms06_trial13_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial13_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial13_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial14_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_rear.mp4\n",
      "Data from 20220728_ms06_trial14_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial14_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial14_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial15_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_rear.mp4\n",
      "Data from 20220728_ms06_trial15_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial15_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial15_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial16_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_rear.mp4\n",
      "Data from 20220728_ms06_trial16_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial16_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial16_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial17_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_rear.mp4\n",
      "Data from 20220728_ms06_trial17_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial17_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial17_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial18_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_rear.mp4\n",
      "Data from 20220728_ms06_trial18_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial18_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial18_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_rear.mp4 using config_file_rear\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownRear4-MingGong-2023-02-10\\dlc-models\\iteration-0\\UpAndDownRear4Feb10-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_rear.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial19_rear DLC_resnet50_UpAndDownRear4Feb10shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_rear.mp4\n",
      "Data from 20220728_ms06_trial19_rear were already filtered. Skipping...\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_lateral.mp4 using config_file_lateral\n",
      "Using snapshot-500000 for model D:\\UpAndDown\\UpAndDownLateral5-MingGong-2023-02-08\\dlc-models\\iteration-0\\Lateral5Feb8-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_lateral.mp4\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos 20220728_ms06_trial19_lateral DLC_resnet50_Lateral5Feb8shuffle1_500000\n",
      "Filtering with median model D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\20220728_ms06_trial19_lateral.mp4\n",
      "Saving filtered csv poses!\n",
      "Undistorting...\n",
      "Computing the triangulation...\n",
      "Triangulated data for video ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']\n",
      "Results are saved under:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\n",
      "All videos were analyzed...\n",
      "Now you can create 3D video(s) using deeplabcut.create_labeled_video_3d\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.triangulate(config_path_3d, r'D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos',\n",
    "                    videotype='.mp4', save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2023-03-25-3d\\\\videos\\\\20220728_ms06_trial01_lateral.mp4']]\n",
      "Creating 3D video from 20220728_ms06_trial01_rear.mp4 and 20220728_ms06_trial01_lateral.mp4 using 20220728_ms06_trial01_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\*20220728_ms06_trial01_rearDLC_resnet50_UpAndDownRear4Feb10shuffle1_500000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos\\*20220728_ms06_trial01_lateralDLC_resnet50_Lateral5Feb8shuffle1_500000*filtered.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 117270 into shape (7999,newaxis,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\UpAndDown\\calibrate_updown_20220728.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/UpAndDown/calibrate_updown_20220728.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m deeplabcut\u001b[39m.\u001b[39;49mcreate_labeled_video_3d(config_path_3d, [\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mD:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUpAndDown\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUpAndDown-Ming-2023-03-25-3d\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mvideos\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UpAndDown/calibrate_updown_20220728.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                  videotype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.mp4\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UpAndDown/calibrate_updown_20220728.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                  start\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, end\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Tytell_Admin\\.conda\\envs\\DEEPLABCUT\\lib\\site-packages\\deeplabcut\\pose_estimation_3d\\plotting3D.py:272\u001b[0m, in \u001b[0;36mcreate_labeled_video_3d\u001b[1;34m(config, path, videofolder, start, end, trailpoints, videotype, view, xlim, ylim, zlim, draw_skeleton, color_by, figsize, fps, dpi)\u001b[0m\n\u001b[0;32m    270\u001b[0m visible1 \u001b[39m=\u001b[39m xy1[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m pcutoff\n\u001b[0;32m    271\u001b[0m xy1[\u001b[39m~\u001b[39mvisible1] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m--> 272\u001b[0m xy2 \u001b[39m=\u001b[39m df_cam2\u001b[39m.\u001b[39;49mloc[:, mask2d]\u001b[39m.\u001b[39;49mto_numpy()\u001b[39m.\u001b[39;49mreshape((\u001b[39mlen\u001b[39;49m(df_cam1), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n\u001b[0;32m    273\u001b[0m visible2 \u001b[39m=\u001b[39m xy2[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m pcutoff\n\u001b[0;32m    274\u001b[0m xy2[\u001b[39m~\u001b[39mvisible2] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 117270 into shape (7999,newaxis,3)"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video_3d(config_path_3d, [r'D:\\UpAndDown\\UpAndDown-Ming-2023-03-25-3d\\videos'],\n",
    "                 videotype='.mp4',\n",
    "                 start=100, end=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEEPLABCUT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "226ff148af80c3b82e59896d21bb9aa616357ea73c2b2cbec1a0ccfea327a692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
